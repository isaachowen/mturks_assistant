{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"4.2_mturkDataCleaner.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","execution_count":null,"source":["## If using Google colab\n","# from google.colab import drive\n","# drive.mount('/content/drive', force_remount=True)\n"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["import pandas as pd\n","import io\n","import numpy as np"],"outputs":[],"metadata":{"id":"2r5RoBaLZZWs","executionInfo":{"status":"ok","timestamp":1619290677476,"user_tz":240,"elapsed":406,"user":{"displayName":"Alicia Bogatin","photoUrl":"","userId":"10704781009943021166"}}}},{"cell_type":"code","execution_count":19,"source":["# Set up read path, read file, write path, write file\n","curr_project_name = \"project_erudition_emails_2\"\n","notebook_path = \"/mnt/c/Users/isaac/Desktop/mturks_assistant_github/mturks_assistant/notebooks\"\n","\n","input_filename = 'Batch_4367564_batch_results.xlsx'\n","read_path = notebook_path+\"/../\"+curr_project_name+\"/5_mOut_clubs/\"+input_filename\n","\n","output_filename = '418_cleaned_mturk_health_emails.xlsx'\n","write_path = notebook_path+\"/../\"+curr_project_name+\"/6_notebookProcessed_clubs/\"+output_filename\n","\n"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            HITId  ... Reject\n","0  34F34TZU83LKK4OLSTP5XBYXRNP2JW  ...    NaN\n","1  34F34TZU83LKK4OLSTP5XBYXRNP2JW  ...    NaN\n","2  34F34TZU83LKK4OLSTP5XBYXRNP2JW  ...    NaN\n","3  34KYK9TV3YU77K77YGRUQ5SOHCESB3  ...    NaN\n","4  34KYK9TV3YU77K77YGRUQ5SOHCESB3  ...    NaN\n","\n","[5 rows x 38 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>HITId</th>\n","      <th>HITTypeId</th>\n","      <th>Title</th>\n","      <th>Description</th>\n","      <th>Keywords</th>\n","      <th>Reward</th>\n","      <th>CreationTime</th>\n","      <th>MaxAssignments</th>\n","      <th>RequesterAnnotation</th>\n","      <th>AssignmentDurationInSeconds</th>\n","      <th>AutoApprovalDelayInSeconds</th>\n","      <th>Expiration</th>\n","      <th>NumberOfSimilarHITs</th>\n","      <th>LifetimeInSeconds</th>\n","      <th>AssignmentId</th>\n","      <th>WorkerId</th>\n","      <th>AssignmentStatus</th>\n","      <th>AcceptTime</th>\n","      <th>SubmitTime</th>\n","      <th>AutoApprovalTime</th>\n","      <th>ApprovalTime</th>\n","      <th>RejectionTime</th>\n","      <th>RequesterFeedback</th>\n","      <th>WorkTimeInSeconds</th>\n","      <th>LifetimeApprovalRate</th>\n","      <th>Last30DaysApprovalRate</th>\n","      <th>Last7DaysApprovalRate</th>\n","      <th>Input.university_name</th>\n","      <th>Input.club_name</th>\n","      <th>Input.club_link</th>\n","      <th>Answer.email_1</th>\n","      <th>Answer.email_2</th>\n","      <th>Answer.facebook</th>\n","      <th>Answer.instagram</th>\n","      <th>Answer.phone_number</th>\n","      <th>Answer.website</th>\n","      <th>Approve</th>\n","      <th>Reject</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>34F34TZU83LKK4OLSTP5XBYXRNP2JW</td>\n","      <td>3C3J03PXDMMF5QZJ4Y9V14SIRPTH78</td>\n","      <td>Gather contact information for the student clu...</td>\n","      <td>Gather all available contact information for a...</td>\n","      <td>data collection, data extraction, student club...</td>\n","      <td>$0.01</td>\n","      <td>Sun Mar 14 20:47:50 PDT 2021</td>\n","      <td>3</td>\n","      <td>BatchId:4367564;OriginalHitTemplateId:928390855;</td>\n","      <td>60</td>\n","      <td>259200</td>\n","      <td>Wed Mar 31 20:50:04 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>39O5D9O871EPKSCRC4RPH0MHDX0C32</td>\n","      <td>A3H70RJNKHWKBD</td>\n","      <td>Approved</td>\n","      <td>Mon Mar 15 19:55:30 PDT 2021</td>\n","      <td>Mon Mar 15 19:55:46 PDT 2021</td>\n","      <td>Thu Mar 18 19:55:46 PDT 2021</td>\n","      <td>Thu Mar 18 19:56:35 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>16</td>\n","      <td>100% (3016/3016)</td>\n","      <td>100% (2414/2414)</td>\n","      <td>0% (0/0)</td>\n","      <td>Texas A&amp;M</td>\n","      <td>Mays Healthcare Alliance</td>\n","      <td>https://maroonlink.tamu.edu/organization/mha</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>34F34TZU83LKK4OLSTP5XBYXRNP2JW</td>\n","      <td>3C3J03PXDMMF5QZJ4Y9V14SIRPTH78</td>\n","      <td>Gather contact information for the student clu...</td>\n","      <td>Gather all available contact information for a...</td>\n","      <td>data collection, data extraction, student club...</td>\n","      <td>$0.01</td>\n","      <td>Sun Mar 14 20:47:50 PDT 2021</td>\n","      <td>3</td>\n","      <td>BatchId:4367564;OriginalHitTemplateId:928390855;</td>\n","      <td>60</td>\n","      <td>259200</td>\n","      <td>Wed Mar 31 20:50:04 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3GU1KF0O4QNDHCP8W2S1JJJ00J1BP1</td>\n","      <td>A2ZKMDAQ3XUVCT</td>\n","      <td>Approved</td>\n","      <td>Wed Mar 17 14:24:39 PDT 2021</td>\n","      <td>Wed Mar 17 14:24:52 PDT 2021</td>\n","      <td>Sat Mar 20 14:24:52 PDT 2021</td>\n","      <td>Sat Mar 20 14:25:07 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13</td>\n","      <td>100% (2888/2888)</td>\n","      <td>100% (2021/2021)</td>\n","      <td>0% (0/0)</td>\n","      <td>Texas A&amp;M</td>\n","      <td>Mays Healthcare Alliance</td>\n","      <td>https://maroonlink.tamu.edu/organization/mha</td>\n","      <td>na</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>34F34TZU83LKK4OLSTP5XBYXRNP2JW</td>\n","      <td>3C3J03PXDMMF5QZJ4Y9V14SIRPTH78</td>\n","      <td>Gather contact information for the student clu...</td>\n","      <td>Gather all available contact information for a...</td>\n","      <td>data collection, data extraction, student club...</td>\n","      <td>$0.01</td>\n","      <td>Sun Mar 14 20:47:50 PDT 2021</td>\n","      <td>3</td>\n","      <td>BatchId:4367564;OriginalHitTemplateId:928390855;</td>\n","      <td>60</td>\n","      <td>259200</td>\n","      <td>Wed Mar 31 20:50:04 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3NQL1CS15ZUMZ4FFS6FKXM6J9XYVYZ</td>\n","      <td>A2XRPDH3WXT29P</td>\n","      <td>Approved</td>\n","      <td>Mon Mar 29 08:55:14 PDT 2021</td>\n","      <td>Mon Mar 29 08:55:21 PDT 2021</td>\n","      <td>Thu Apr 01 08:55:21 PDT 2021</td>\n","      <td>Thu Apr 01 08:55:42 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>7</td>\n","      <td>100% (211/211)</td>\n","      <td>100% (211/211)</td>\n","      <td>0% (0/0)</td>\n","      <td>Texas A&amp;M</td>\n","      <td>Mays Healthcare Alliance</td>\n","      <td>https://maroonlink.tamu.edu/organization/mha</td>\n","      <td>g</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>34KYK9TV3YU77K77YGRUQ5SOHCESB3</td>\n","      <td>3C3J03PXDMMF5QZJ4Y9V14SIRPTH78</td>\n","      <td>Gather contact information for the student clu...</td>\n","      <td>Gather all available contact information for a...</td>\n","      <td>data collection, data extraction, student club...</td>\n","      <td>$0.01</td>\n","      <td>Sun Mar 14 20:47:51 PDT 2021</td>\n","      <td>3</td>\n","      <td>BatchId:4367564;OriginalHitTemplateId:928390855;</td>\n","      <td>60</td>\n","      <td>259200</td>\n","      <td>Sun Mar 21 20:47:51 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>33SA9F9TR5G18OYTIF8MCLXHWE2EWM</td>\n","      <td>A2ZKMDAQ3XUVCT</td>\n","      <td>Approved</td>\n","      <td>Wed Mar 17 18:50:41 PDT 2021</td>\n","      <td>Wed Mar 17 18:50:56 PDT 2021</td>\n","      <td>Sat Mar 20 18:50:56 PDT 2021</td>\n","      <td>Sat Mar 20 18:51:10 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>15</td>\n","      <td>100% (2888/2888)</td>\n","      <td>100% (2021/2021)</td>\n","      <td>0% (0/0)</td>\n","      <td>Texas A&amp;M</td>\n","      <td>Healthcare Finance Association</td>\n","      <td>https://maroonlink.tamu.edu/organization/healt...</td>\n","      <td>na</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>34KYK9TV3YU77K77YGRUQ5SOHCESB3</td>\n","      <td>3C3J03PXDMMF5QZJ4Y9V14SIRPTH78</td>\n","      <td>Gather contact information for the student clu...</td>\n","      <td>Gather all available contact information for a...</td>\n","      <td>data collection, data extraction, student club...</td>\n","      <td>$0.01</td>\n","      <td>Sun Mar 14 20:47:51 PDT 2021</td>\n","      <td>3</td>\n","      <td>BatchId:4367564;OriginalHitTemplateId:928390855;</td>\n","      <td>60</td>\n","      <td>259200</td>\n","      <td>Sun Mar 21 20:47:51 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3PWWM24LH0KYN7QVRSXFW4L6HOZ82T</td>\n","      <td>AR63X44649Y4Q</td>\n","      <td>Approved</td>\n","      <td>Mon Mar 15 10:53:58 PDT 2021</td>\n","      <td>Mon Mar 15 10:54:15 PDT 2021</td>\n","      <td>Thu Mar 18 10:54:15 PDT 2021</td>\n","      <td>Thu Mar 18 10:54:28 PDT 2021</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>17</td>\n","      <td>100% (552/552)</td>\n","      <td>0% (0/0)</td>\n","      <td>0% (0/0)</td>\n","      <td>Texas A&amp;M</td>\n","      <td>Healthcare Finance Association</td>\n","      <td>https://maroonlink.tamu.edu/organization/healt...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"tags":[]},"execution_count":19}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"id":"OxBb5VXixzLD","executionInfo":{"status":"ok","timestamp":1619290986822,"user_tz":240,"elapsed":595,"user":{"displayName":"Alicia Bogatin","photoUrl":"","userId":"10704781009943021166"}},"outputId":"65811f8e-bf59-45f9-c377-feba1a4c4f1f"}},{"cell_type":"markdown","source":["## Read in MTurks dataframe and do preliminary reformatting and unstacking of data"],"metadata":{"id":"YqU0neLGfll1"}},{"cell_type":"code","execution_count":20,"source":["df = pd.read_excel(read_path)\n","\n","# Clean NANs\n","print('df nan values: ',df.isnull().sum().sum())\n","df = df.fillna('N/A')\n","print('df nan values: ',df.isnull().sum().sum())\n","# data.drop(columns='Unnamed: 0',inplace=True)\n","\n","# Unstacking of the data side by side \n","df['copy_id'] = -1\n","\n","dfgroups = df.groupby(['Input.university_name','Input.club_name']).size().reset_index().rename(columns={0:'count'})\n","\n","for i, x in dfgroups.iterrows():\n","  uni = x['Input.university_name']\n","  club = x['Input.club_name']\n","  df_zoom = df.loc[(df['Input.university_name']==uni) & (df['Input.club_name'] == club)]\n","    \n","  ctr = 1\n","  for j, y in df_zoom.iterrows():\n","    df.at[j,'copy_id'] = ctr\n","    ctr += 1\n","\n","df2 = df.set_index(['Input.university_name','Input.club_name','copy_id'])\n","df2 = df2.unstack('copy_id')\n","\n","# Clean NANs\n","print('df2 nan values: ',df2.isnull().sum().sum())\n","df2 = df2.fillna('N/A')\n","print('df2 nan values: ',df2.isnull().sum().sum())\n","\n","# Removing all unnecessary columns for coming analysis\n","# KEEP ALL INPUT DATA FOR LATER CHECKING (all inputs, all answers, hitid, workerid)\n","df3 = df2[['HITId','WorkerId','Input.directory_link', 'Input.university_name', 'Input.country','Input.city','Answer.club_name','Answer.club_link',]]\n","print('df3 nan values: ',df3.isnull().sum().sum())\n","df3 = df3.fillna('N/A')\n","print('df3 nan values: ',df3.isnull().sum().sum())"],"outputs":[{"output_type":"stream","name":"stdout","text":["df nan values:  93757\n","df nan values:  0\n","df2 nan values:  368568\n","df2 nan values:  0\n","df3 nan values:  0\n","df3 nan values:  0\n"]}],"metadata":{"id":"1gDEDTUct9Bd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619291042037,"user_tz":240,"elapsed":7882,"user":{"displayName":"Alicia Bogatin","photoUrl":"","userId":"10704781009943021166"}},"outputId":"0d3de17d-d4b2-4da2-f868-557a0cc7bd20"}},{"cell_type":"code","execution_count":null,"source":["# get a specific column\n","# df3.loc[:,'Answer.email_1'][1]\n","\n","mining_items = {}\n","mining_items['email_1'] = '@'\n","mining_items['email_2'] = '@'\n","# minint_items['facebook] = ''\n","# mining_items['instagram'] '@'\n","# mining_items['website'] = ''\n","# mining_items['phone_number']\n","redundancy = 3 # the redundancy is built into this it will take alot of work to automate this for more or less redundancy\n","prefix = 'Answer.'\n","\n","for item in mining_items:\n","  print(\"item: \",item,' anchor: ',mining_items[item])\n","  anchor = mining_items[item]\n","\n","  for index, row in df3.iterrows():\n","   # print(\"index \",index)\n","   # print(\"row item\")\n","   # print(row['HITId'][1])\n","\n","    \n","    # Case 1: All 3 are the same\n","    #if (row['1'+infix+item] == row['2'+infix+item] and row['1'+infix+item] == row['3'+infix+item]):\n","    if (row[prefix+item][1] == row[prefix+item][2] and row[prefix+item][1] == row[prefix+item][3]):\n","      #if ( anchor in row['1'+infix+item]):\n","      if ( anchor in row[prefix+item][1]):\n","        #row['Winner_'+item] = row['1'+infix+item]\n","        df3.loc[index, ('results','winner_'+item)] = row[prefix+item][1]\n","        #row[item+'flag'] = 'All good, triple consensus'\n","        df3.loc[index,('results','flag_'+item)] = 'All good, triple consensus'\n","        #row['Email_1_list'] = ''\n","        df3.loc[index,('results','list_'+item)] = ''\n","      else:\n","        #row['Winner_'+item] = 'N/A'\n","        df3.loc[index,('results','winner_'+item)] = 'N/A'\n","        #row[item+'_flag'] = 'All good, triple consensus'\n","        df3.loc[index,('results','flag_'+item)] = 'All good, triple consensus'\n","        #row[item+'_list'] = ''\n","        df3.loc[index,('results','list_'+item)] = ''\n","\n","### checkpoint\n","\n","    # Case 2: All 3 are different\n","    elif (row[prefix+item][1] != row[prefix+item][2] and row[prefix+item][1] != row[prefix+item][3] and row[prefix+item][2] != row[prefix+item][3]):\n","      templist = []\n","      #print(row[prefix+item][1])\n","      #print(row[prefix+item][2])\n","      #print(row[prefix+item][3])\n","      #print(type(row[prefix+item][3]))\n","\n","      if (anchor in row[prefix+item][1]):\n","        templist.append(row[prefix+item][1])\n","\n","      if (anchor in row[prefix+item][2]):\n","        templist.append(row[prefix+item][2])\n","\n","      if (anchor in row[prefix+item][3]):\n","        templist.append(row[prefix+item][3])\n","\n","      if len(templist) == 0:\n","        # row['winner'+item]='N/A'\n","        df3.loc[index,('results','winner_'+item)] = 'N/A'\n","        # row['flag_'+item] = 'All good, zero value'\n","        df3.loc[index,('results','flag_'+item)] = 'All good, zero value'\n","        # row['list_'+item] = ''\n","        df3.loc[index,('results','list_'+item)] = ''\n","\n","      if len(templist) == 1:\n","        # row['winner'+item]=templist[0]\n","        df3.loc[index,('results','winner_'+item)] = templist[0]\n","        # row['flag'+item] = 'Checkit, minority'\n","        df3.loc[index,('results','flag_'+item)] = 'Checkit, minority'\n","        # row['list'+item] = ''\n","        df3.loc[index,('results','list_'+item)] = ''\n","\n","      if len(templist) == 2:\n","        # row['winner'+item] = \",\".join(templist)\n","        df3.loc[index,('results','winner_'+item)] = \",\".join(templist)\n","        # row['flag'+item] = 'Checkit, multiple emails'\n","        df3.loc[index,('results','flag_'+item)] = 'Checkit, multiple emails'\n","        # row['list'+item] = ''\n","        df3.loc[index,('results','list_'+item)] = ''\n","    \n","      if len(templist) == 3:\n","        df3.loc[index,('results','winner_'+item)] = \",\".join(templist)\n","        df3.loc[index,('results','flag_'+item)] = 'Checkit, multiple emails'\n","        df3.loc[index,('results','list_'+item)] = ''\n","        \n","## Checkpoint\n","\n","\n","    # Case 3: 2 are the same and 1 is different\n","    #elif row['1'+infix+item] == row['2'+infix+item]: # implicitly, the odd one out is not equal\n","    elif row[prefix+item][1] == row[prefix+item][2]: # implicitly, the odd one out is not equal\n","      # if (anchor in row['1'+infix+item]): # there is an @ in the overlap\n","      if (anchor in row[prefix+item][1]): # there is an @ in the overlap\n","        if (anchor in row[prefix+item][3]): # if there is an @ in the odd one out, we should take a look\n","          #row['winner'+item] = \",\".join([row[prefix+item][1],row[prefix+item][3]]) #row['1'+infix+item],row['3'+infix+item]])\n","          df3.loc[index,('results','winner_'+item)] = \",\".join([row[prefix+item][1],row[prefix+item][3]]) #row['1'+infix+item],row['3'+infix+item]])\n","          # row['flag'+item] = 'Checkit, multiple emails'\n","          df3.loc[index,('results','flag_'+item)] = 'Checkit, multiple emails'\n","          # row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","\n","        else: # there is no @ in the odd one out\n","          # row['winner'+item] = row['1'+infix+item]\n","          df3.loc[index,('results','winner_'+item)] = row[prefix+item][1]\n","          #row['flag'+item] = 'All good, double consensus'\n","          df3.loc[index,('results','flag_'+item)] = row[prefix+item][1]\n","          # row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","      \n","      else: # there is no @ in the two that overlap\n","        if anchor in row[prefix+item][3]: #row['3'+infix+item]: # if there is an @ in the odd one out, we should take a look\n","          # row['winner'+item] = row['3'+infix+item]\n","          df3.loc[index,('results','winner_'+item)] = row[prefix+item][3]\n","          # row['flag'+item] = 'Checkit, minority'\n","          df3.loc[index,('results','flag_'+item)]\n","          # row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","\n","        else: # there is no @ in the odd one out or the overlaps\n","          # row['winner'+item] = 'N/A'\n","          df3.loc[index,('results','winner_'+item)] = 'N/A'\n","          # row['flag'+item] = 'All good, zero value'\n","          df3.loc[index,('results','flag_'+item)] = 'All good, zero value'\n","          # row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","      # print('hi')\n","    \n","## Checkpoint    \n","    # elif (row['1'+infix+item] == row['3'+infix+item]):\n","    elif (row[prefix+item][1] == row[prefix+item][3]):\n","    \n","      if (anchor in row[prefix+item][1]): # there is an @ in the overlap\n","        if (anchor in row[prefix+item][2]): # if there is an @ in the odd one out, we should take a look\n","          # row['winner'+item] = ','.join([row['1'+infix+item],row['2'+infix+item]])\n","          df3.loc[index,('results','winner_'+item)] = ','.join([row[prefix+item][1],row[prefix+item][2]])\n","          # row['flag'+item] = 'Checkit, multiple emails'\n","          df3.loc[index,('results','flag_'+item)] = 'Checkit, multiple emails'\n","          # row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","        else: # there is no @ in the odd one out\n","          # row['winner'+item] = row['1'+infix+item]\n","          df3.loc[index,('results','winner_'+item)] = row[prefix+item][1]\n","          \n","          #row['flag'+item] = 'All good, double consensus'\n","          df3.loc[index,('results','flag_'+item)] = 'All good, double consensus'\n","          \n","          #row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","\n","      else: # there is no @ in the two that overlap\n","        if anchor in row[prefix+item][2]: # if there is an @ in the odd one out, we should take a look\n","          \n","          # row['winner'+item] = row['2'+infix+item]\n","          df3.loc[index,('results','winner_'+item)] = row[prefix+item][2]\n","          \n","          # row['flag'+item] = 'Checkit, minority'\n","          df3.loc[index,('results','flag_'+item)] = 'Checkit, minority'\n","          \n","          # row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","\n","        else: # there is no @ in the odd one out or the overlaps\n","          # row['winner'+item] = 'N/A'\n","          df3.loc[index,('results','winner_'+item)] = 'N/A'\n","\n","          # row['flag'+item] = 'All good, zero value'\n","          df3.loc[index,('results','flag_'+item)] = 'All good, zero value'\n","\n","          # row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","\n","      # print('ho')\n","\n","## Checkpoint\n","    #elif (row['2'+infix+item] == row['3'+infix+item]):\n","    elif (row[prefix+item][2] == row[prefix+item][3]):\n","      \n","      #if (anchor in row['2'+infix+item]): # there is an @ in the overlap\n","      if (anchor in row[prefix+item][2]): # there is an @ in the overlap\n","\n","        #if (anchor in row['1'+infix+item]): # if there is an @ in the odd one out, we should take a look\n","        if (anchor in row[prefix+item][1]): # if there is an @ in the odd one out, we should take a look\n","          #row['winner'+item] = ','.join([row['2'+infix+item],row['1'+infix+item]])\n","          df3.loc[index,('results','winner_'+item)] = ','.join([row[prefix+item][2],row[prefix+item][1]])\n","\n","          #row['flag'+item] = 'Checkit, multiple emails'\n","          df3.loc[index,('results','flag_'+item)] = 'Checkit, multiple emails'\n","\n","          #row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","\n","        else: # there is no @ in the odd one out\n","          # row['winner'+item] = row['2'+infix+item]\n","          df3.loc[index,('results','list_'+item)] = row[prefix+item][2]\n","          \n","          # row['flag'+item] = 'All good, double consensus'\n","          df3.loc[index,('results','flag_'+item)] = 'All good, double consensus'\n","\n","          # row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","\n","## checkpoint    \n","      else: # there is no @ in the two that overlap\n","        #if anchor in row['1'+infix+item]: # if there is an @ in the odd one out, we should take a look\n","        if anchor in row[prefix+item][1]: #['1'+infix+item]: # if there is an @ in the odd one out, we should take a look\n","          #row['winner'+item] = row['1'+infix+item]\n","          df3.loc[index,('results','winner_'+item)] = row[prefix+item][1]\n","\n","          # row['flag'+item] = 'Checkit, minority'\n","          df3.loc[index,('results','flag_'+item)] = 'Checkit, minority'\n","\n","          # row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","\n","        else: # there is no @ in the odd one out or the overlaps\n","          #row['winner'+item] = 'N/A'\n","          df3.loc[index,('results','winner_'+item)] = 'N/A'\n","\n","          #row['flag'+item] = 'All good, zero value'\n","          df3.loc[index,('results','flag_'+item)] = 'All good, zero value'\n","\n","          #row['list'+item] = ''\n","          df3.loc[index,('results','list_'+item)] = ''\n","\n","      # print('he')\n","    \n","\n","\n","#      print('hi')\n","#      print(row['1_Answer.email_1'])\n","#      print(row['2_Answer.email_1'])\n","#      print(row['3_Answer.email_1'])\n","\n","    # row['Email_1_list'] = 4\n","    # print(row['c1'], row['c2'])\n","\n","'''\n","'''"],"outputs":[{"output_type":"stream","name":"stdout","text":["item:  email_1  anchor:  @\n","item:  email_2  anchor:  @\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{"tags":[]},"execution_count":32}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"RhwUi0NG32SE","executionInfo":{"status":"ok","timestamp":1618805823353,"user_tz":240,"elapsed":19339,"user":{"displayName":"Isaac Howenstine","photoUrl":"","userId":"11451223383071804098"}},"outputId":"68f0d051-d099-4bb3-87a1-f8cf408e9d61"}},{"cell_type":"code","execution_count":null,"source":["# get a specific column\n","df_emails = df3.loc[:,[('results','winner_email_1'),('results','flag_email_1'),('results','winner_email_2'),('results','flag_email_2')]]\n","df_emails = df_emails.fillna('N/A')\n","df_emails.head()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                      results  ...                            \n","copy_id                                                                        winner_email_1  ...                flag_email_2\n","Input.university_name        Input.club_name                                                   ...                            \n","Albany State University      N/A                                                          N/A  ...  All good, triple consensus\n","Allegany College of Maryland N/A                                                          N/A  ...  All good, triple consensus\n","Arizona State University     Active Minds at Arizona State University        gcarnesi@asu.edu  ...  All good, triple consensus\n","                             Alpha Epsilon Delta                                          N/A  ...  All good, triple consensus\n","                             American Medical Student Association - W  amsa.asuwest@gmail.com  ...  All good, triple consensus\n","\n","[5 rows x 4 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"4\" halign=\"left\">results</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th>copy_id</th>\n","      <th>winner_email_1</th>\n","      <th>flag_email_1</th>\n","      <th>winner_email_2</th>\n","      <th>flag_email_2</th>\n","    </tr>\n","    <tr>\n","      <th>Input.university_name</th>\n","      <th>Input.club_name</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Albany State University</th>\n","      <th>N/A</th>\n","      <td>N/A</td>\n","      <td>All good, zero value</td>\n","      <td>N/A</td>\n","      <td>All good, triple consensus</td>\n","    </tr>\n","    <tr>\n","      <th>Allegany College of Maryland</th>\n","      <th>N/A</th>\n","      <td>N/A</td>\n","      <td>All good, triple consensus</td>\n","      <td>N/A</td>\n","      <td>All good, triple consensus</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"3\" valign=\"top\">Arizona State University</th>\n","      <th>Active Minds at Arizona State University</th>\n","      <td>gcarnesi@asu.edu</td>\n","      <td>Checkit, minority</td>\n","      <td>N/A</td>\n","      <td>All good, triple consensus</td>\n","    </tr>\n","    <tr>\n","      <th>Alpha Epsilon Delta</th>\n","      <td>N/A</td>\n","      <td>All good, double consensus</td>\n","      <td>N/A</td>\n","      <td>All good, triple consensus</td>\n","    </tr>\n","    <tr>\n","      <th>American Medical Student Association - W</th>\n","      <td>amsa.asuwest@gmail.com</td>\n","      <td>All good, double consensus</td>\n","      <td>N/A</td>\n","      <td>All good, triple consensus</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"tags":[]},"execution_count":33}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"0qs5TcXk5xKl","executionInfo":{"status":"ok","timestamp":1618805831500,"user_tz":240,"elapsed":258,"user":{"displayName":"Isaac Howenstine","photoUrl":"","userId":"11451223383071804098"}},"outputId":"a40136db-1b9c-41d5-d4c2-0d955dfd6dd2"}},{"cell_type":"markdown","source":["##Connect the columns together, making the database you need (and maybe keeping IDs to link the data with other data later)"],"metadata":{"id":"iYXmJfP3WhYp"}},{"cell_type":"code","execution_count":null,"source":["df_emails_large = pd.DataFrame(columns=['university','club','winner_email','flag','list_id'])\n","email_items = ['email_1','email_2']\n","\n","for item in email_items:\n","  for index, row in df_emails.iterrows():\n","    university = index[0]\n","    club = index[1]\n","    if ',' in row[('results','winner_'+item)]:\n","      # create list of emails\n","      templist = row[('results','winner_'+item)].split(',')\n","      # add emails to new dataframe\n","      \n","      for email in templist:\n","        email = email\n","        flag = row[('results','flag_'+item)]\n","        dftemp = pd.DataFrame([[university,club,email,flag,item]],columns=['university','club','winner_email','flag','list_id'])\n","        # print(dftemp)\n","        # print('\\n\\n')\n","        df_emails_large = df_emails_large.append(dftemp)\n","\n","    else:\n","      # add emails to new dataframe\n","      email= row[('results','winner_'+item)]\n","      flag = row[('results','flag_'+item)]\n","      dftemp2 = pd.DataFrame([[university,club,email,flag,item]] ,columns=['university','club','winner_email','flag','list_id'])\n","      # print(dftemp2)\n","      # print('\\n\\n')\n","      df_emails_large = df_emails_large.append(dftemp2)\n","\n","'''\n","    print('issue')\n","    print(row[('results','winner_email_1')])\n","    print('index: ',index)\n","    print('\\n')\n","'''\n","    # print(row[('results','winner_email_1')])\n","\n","    # df_emails_large.loc[df_emails_large['list_id']=='email_2']\n","df_emails_large = df_emails_large.fillna('N/A')\n","df_emails_large = df_emails_large.loc[df_emails_large['winner_email']!='N/A']"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n    print('issue')\\n    print(row[('results','winner_email_1')])\\n    print('index: ',index)\\n    print('\\n')\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{"tags":[]},"execution_count":34}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"9NPsYYMD694f","executionInfo":{"status":"ok","timestamp":1618805848893,"user_tz":240,"elapsed":10948,"user":{"displayName":"Isaac Howenstine","photoUrl":"","userId":"11451223383071804098"}},"outputId":"c07e58f1-ca15-4f21-9dfe-3f98ff4089d2"}},{"cell_type":"markdown","source":["## Export the dataframe"],"metadata":{"id":"O4g3vohsWmMi"}},{"cell_type":"code","execution_count":null,"source":["df_emails_large.to_excel(write_path)"],"outputs":[],"metadata":{"id":"oe49Iss_HuHp"}}]}